var documenterSearchIndex = {"docs":
[{"location":"ref/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"ref/#ESM_PINO.BurgersFD","page":"Reference","title":"ESM_PINO.BurgersFD","text":"BurgersFD{T}\n\nFinite-difference matrices for discretising the 1D Burgers equation using periodic boundary conditions.\n\nInitialization\n\nBurgersFD(T, n, Δx=1)   BurgersFD(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Second-derivative (Laplacian) matrix with periodic BCs\nM2::AbstractMatrix{T}: First-derivative (central differences) matrix with periodic BCs\n\nDetails\n\nM approximates ∂²/∂x² with periodic wrap-around.\nM2 approximates ∂/∂x using central differences and periodic wrap-around.\nUse these matrices for semi-discrete formulations of Burgers’ equation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.BurgersFD2","page":"Reference","title":"ESM_PINO.BurgersFD2","text":"BurgersFD2{T}\n\nFinite-difference matrices for the 1D Burgers equation with periodic boundary conditions using a backward-difference discretisation for the convective (first-derivative) term.\n\nInitialization\n\nBurgersFD2(T, n, Δx=1)   BurgersFD2(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Second-derivative (Laplacian) matrix with periodic BCs\nM2::AbstractMatrix{T}: First-derivative matrix using backward differences (periodic BCs)\n\nDetails\n\nM is identical in form to BurgersFD's Laplacian (periodic).\nM2 is a backward-difference approximation of ∂/∂x; can improve stability for convection-dominated flows.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.BurgersFD_Dirichlet","page":"Reference","title":"ESM_PINO.BurgersFD_Dirichlet","text":"BurgersFD_Dirichlet{T}\n\nFinite-difference matrices for the 1D Burgers equation with Dirichlet boundary conditions.\n\nInitialization\n\nBurgersFD_Dirichlet(T, n, Δx=1)   BurgersFD_Dirichlet(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Second-derivative matrix with Dirichlet enforcement at boundaries\nM2::AbstractMatrix{T}: First-derivative matrix with boundary rows/cols zeroed\n\nDetails\n\nBoundary rows/columns are zeroed to reflect fixed-value (Dirichlet) conditions.\nIntended for Burgers’ problems with fixed boundary values (e.g., u=0 at domain ends).\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.ChannelMLP","page":"Reference","title":"ESM_PINO.ChannelMLP","text":"ChannelMLP(channels::Int; expansion_factor=2.0, activation=gelu)\n\nImplements a channel-wise MLP with a skip connection.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\nchannels: Number of input/output channels\nexpansion_factor: Factor to expand hidden layer size (default: 2.0)\nactivation: Nonlinear activation function in hidden layer (default: NNlib.gelu)\n\nFields\n\nmlp::M: Two-layer Conv-based MLP with hidden dimension = expansion_factor * channels\nskip::S: Skip connection implemented as a SoftGating layer\nexpansion_factor::Number: Factor controlling hidden dimension size\n\nDetails\n\nExpands channels with a 1x1 convolution, applies nonlinearity, then projects back\nAdds gated skip connection to stabilize training\nFunctions similarly to a feed-forward block in transformers\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.ChannelMLP1D","page":"Reference","title":"ESM_PINO.ChannelMLP1D","text":"ChannelMLP1D(channels::Int; expansion_factor=0.5, activation=gelu)\n\nImplements a channel-wise MLP with a skip connection.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.ChannelMLP3D","page":"Reference","title":"ESM_PINO.ChannelMLP3D","text":"ChannelMLP3D(channels::Int; expansion_factor=0.5, activation=gelu)\n\nImplements a channel-wise MLP with a skip connection.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FDPhysicsLossParameters","page":"Reference","title":"ESM_PINO.FDPhysicsLossParameters","text":"FDPhysicsLossParameters(ν::Float64, N_t::Int, t_max::Float64, t_min::Float64, Δt::Float64, x_σ::Float64, x_μ::Float64, M1_gpu::AbstractArray, M2_gpu::AbstractArray)\n\nCreate a struct to hold parameters for finite difference physics loss.\n\nFields\n\nν: Viscosity (scalar)\n'tsteplength`: Time step length (scalar)\nM1_gpu: Second derivative FD matrix (GPU array)\nM2_gpu: First derivative FD matrix (GPU array)\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FNO_Block","page":"Reference","title":"ESM_PINO.FNO_Block","text":"FNO_Block(channels::Int, modes::NTuple{2,Int}; expansion_factor=2, activation=gelu)\n\nA block that combines a SpectralKernel with a ChannelMLP.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\nchannels: Number of input/output channels\nmodes: Tuple specifying number of low-frequency modes for the spectral convolution\nexpansion_factor: Factor controlling hidden dimension size in ChannelMLP (default: 2)\nactivation: Nonlinear activation function (default: NNlib.gelu)\n\nFields\n\nspectral_kernel::SpectralKernel: Combines spectral and spatial convolutions\nchannel_mlp::ChannelMLP: Channel-wise MLP with skip connection\nchannels::Int: Number of channels\nmodes::NTuple{2,Int}: Retained Fourier modes\n\nDetails\n\nApplies spectral kernel to mix global/local features\nFollows with a channel MLP for nonlinear channel mixing\nForms the core computational unit of a Fourier Neural Operator\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FNO_Block1D","page":"Reference","title":"ESM_PINO.FNO_Block1D","text":"FNO_Block1D\n\nA block that combines a spectral kernel with a channel MLP. \n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FNO_Block3D","page":"Reference","title":"ESM_PINO.FNO_Block3D","text":"FNO_Block3D\n\nA block that combines a spectral kernel with a channel MLP. \n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FourierNeuralOperator","page":"Reference","title":"ESM_PINO.FourierNeuralOperator","text":"FourierNeuralOperator <: Lux.AbstractLuxContainerLayer\n\nA Fourier Neural Operator (FNO) container that optionally includes positional embeddings, lifting and projection convolutions, and a stack of FNO blocks.\n\n#Arguments -in_channels::Int: Number of input channels. -out_channels::Int: Number of output channels. -hidden_channels::Int=32: Number of hidden channels used inside FNO blocks. -n_modes::NTuple{N,Int}=(16, 16): Number of retained Fourier modes per spatial dimension. -n_layers::Int=4: Number of FNO blocks to stack. -lifting_channel_ratio::Int=2: Channel expansion ratio used in the lifting layer. -projection_channel_ratio::Int=2: Channel expansion ratio used in the projection layer. -channel_mlp_expansion::Number=2: Expansion factor inside ChannelMLP of each block. -activation=NNlib.gelu: Activation function used in conv layers. -positional_embedding::AbstractString=\"grid\": Choice of positional embedding: \"grid\", \"nogrid\" => 2D variants (GridEmbedding2D or NoOpLayer) \"grid1D\", \"nogrid1D\" => 1D variants (GridEmbedding1D or NoOpLayer) \"grid3D\", \"no_grid3D\" => 3D variants (GridEmbedding3D or NoOpLayer)\n\n#Fields -embedding: Positional embedding layer (a GridEmbeddingND or NoOpLayer). -lifting: Lifting convolution(s) mapping inchannels -> hiddenchannels. -fno_blocks: Repeated stack of FNO blocks appropriate to dimensionality. -projection: Projection convolution(s) mapping hiddenchannels -> outchannels.\n\n#Examples\n\nExample (2D data with grid embedding):\n\nusing Lux, Random, NNlib\n\nrng = Random.default_rng()\n\nlayer = FourierNeuralOperator(\n    in_channels=3,\n    out_channels=2,\n    hidden_channels=32,\n    n_modes=(12, 12),\n    n_layers=4,\n    positional_embedding=\"grid\"\n)\n\nps = Lux.initialparameters(rng, layer)\nst = Lux.initialstates(rng, layer)\n\n# Input tensor (H, W, C, Batch)\nx = randn(Float32, 64, 64, 3, 10)\n\ny, st_new = layer(x, ps, st)\n@show size(y)   # expect (64, 64, 2, 10)\n\nExample (1D data without grid embedding):\n\nlayer1d = FourierNeuralOperator(\n    in_channels=1,\n    out_channels=1,\n    hidden_channels=16,\n    n_modes=(8,),\n    n_layers=3,\n    positional_embedding=\"no_grid1D\"\n)\n\nx1 = randn(Float32, 128, 1, 5)   # (L, C, Batch)\ny1, _ = layer1d(x1,\n    Lux.initialparameters(rng, layer1d),\n    Lux.initialstates(rng, layer1d)\n)\n@show size(y1)   # expect (128, 1, 5)\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.Grid","page":"Reference","title":"ESM_PINO.Grid","text":"Grid{T}\n\nDiscretization grid for 1D finite difference schemes.\n\nInitialization\n\nGrid(x)\n\nwith x an array or range with constant spacing.\n\nArguments\n\nx::AbstractVector{T}: Discretization points, assumed uniformly spaced.\n\nFields\n\nN::Int: Number of grid points\nx::AbstractVector{T}: Coordinates of grid points\nΔx::T: Grid spacing, computed from x\n\nDetails\n\nComputes Δx as the absolute difference between the first two grid points.\nUseful for constructing finite-difference scheme matrices.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.GridEmbedding2D","page":"Reference","title":"ESM_PINO.GridEmbedding2D","text":"GridEmbedding2D(grid_boundaries=[[0f0, 1f0], [0f0, 1f0]])\n\nPositional embedding that appends normalized 2D coordinates to the input.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\ngrid_boundaries: Vector of two intervals [x_min, x_max], [y_min, y_max] specifying coordinate range along each axis\n\nFields\n\nboundaries_x::Vector{Float32}: Range boundaries for x-coordinate\nboundaries_y::Vector{Float32}: Range boundaries for y-coordinate\n\nDetails\n\nConstructs a 2D meshgrid of coordinates normalized to [x_min, x_max] × [y_min, y_max]\nRepeats coordinate grids across batch dimension\nConcatenates grid_x and grid_y as extra channels to the input\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.GridEmbedding3D","page":"Reference","title":"ESM_PINO.GridEmbedding3D","text":"GridEmbedding3D(grid_boundaries=[[0f0, 1f0], [0f0, 1f0], [0f0, 1f0]])\n\nPositional embedding that appends a normalized 3D coordinate grid to input data.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.NeumannFD","page":"Reference","title":"ESM_PINO.NeumannFD","text":"NeumannFD{T}\n\nFinite-difference operator for the first derivative with Neumann boundary conditions (enforcing zero derivative at the boundaries).\n\nInitialization\n\nNeumannFD(T, n, Δx=1)   NeumannFD(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type (e.g. Float64, Float32)\nn::Integer: Number of grid points\nΔx::Number: Grid spacing (default: 1)\ngrid::Grid{T}: Grid object containing N and Δx\n\nFields\n\nM::AbstractMatrix{T}: Finite-difference matrix representing the derivative operator\n\nDetails\n\nImplements central differences for the interior and modifies boundary rows to enforce zero slope.\nThe returned operator approximates ∂/∂x with Neumann BCs.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.PeriodicFD","page":"Reference","title":"ESM_PINO.PeriodicFD","text":"PeriodicFD{T}\n\nFinite-difference operator for the first derivative with periodic boundary conditions.\n\nInitialization\n\nPeriodicFD(T, n, Δx=1)   PeriodicFD(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing (default: 1)\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Finite-difference matrix representing the derivative operator\n\nDetails\n\nImplements central differences and wraps the stencil at the domain boundaries (periodic).\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SoftGating","page":"Reference","title":"ESM_PINO.SoftGating","text":"SoftGating(channels::Int)\n\nA soft gating layer that applies per-channel multiplicative scaling.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\nchannels: Number of channels in the input\n\nFields\n\nchannels::Int: Number of channels\n\nDetails\n\nLearns a single scalar weight per channel\nWeights are initialized to 1.0 (identity scaling)\nUseful for lightweight residual or skip connections\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SoftGating1D","page":"Reference","title":"ESM_PINO.SoftGating1D","text":"SoftGating1D(channels::Int)\n\nA soft gating layer that applies per-channel multiplicative scaling.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SoftGating3D","page":"Reference","title":"ESM_PINO.SoftGating3D","text":"SoftGating3D(channels::Int)\n\nA soft gating layer that applies per-channel multiplicative scaling.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralConv","page":"Reference","title":"ESM_PINO.SpectralConv","text":"SpectralConv{T,N}\n\nSpectral convolution layer for Fourier Neural Operator in Lux.jl. Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nin_channels: Number of input channels\nout_channels: Number of output channels\nmodes: Tuple specifying number of low-frequency modes to retain along each spatial dimension\nT: Data type for weights (default: ComplexF32)\nN: Number of spatial dimensions (inferred from length of modes)\n\n#Fields\n\nin_channels::Int: Number of input channels\nout_channels::Int: Number of output channels\nmodes::NTuple{N,Int}: Number of low-frequency modes to retain along each spatial dimension\n\nDetails\n\nUses FFT to transform input to frequency domain, applies learned complex weights to low-frequency modes, and transforms back to spatial domain\nPads output back to original spatial dimensions after truncation\nWeights are initialized with Glorot-like scaling\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralKernel","page":"Reference","title":"ESM_PINO.SpectralKernel","text":"SpectralKernel{P,F}\n\nCombines a SpectralConv layer with a 1x1 convolution in parallel, followed by an activation function.   Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nin_ch: Number of input channels\nout_ch: Number of output channels\nmodes: Tuple specifying number of low-frequency modes to retain in the spectral branch\nactivation: Activation function applied after combining spatial and spectral branches (default: NNlib.gelu)\n\nFields\n\nspatial_conv::P: 1x1 convolution operating directly in the spatial domain\nspectral_conv::SpectralConv: Spectral convolution layer\nactivation::F: Elementwise activation function\n\nDetails\n\nThe input is processed in parallel by a 1x1 convolution and a spectral convolution\nOutputs from both branches are summed and passed through the activation\nUseful for mixing local (spatial) and global (spectral) information\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralKernel1D","page":"Reference","title":"ESM_PINO.SpectralKernel1D","text":"SpectralKernel1D{P,F}\nCombines a SpectralConv layer with a 1x1 convolution in parallel, followed by an activation function.\n\nExpects input in (spatial, channel, batch) format.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralKernel3D","page":"Reference","title":"ESM_PINO.SpectralKernel3D","text":"SpectralKernel3D{P,F}\n\nCombines a SpectralConv layer with a 1x1 convolution in parallel, followed by an activation function. Expects input in (spatial..., channel, batch) format.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralPhysicsLossParameters","page":"Reference","title":"ESM_PINO.SpectralPhysicsLossParameters","text":"SpectralPhysicsLossParameters(ν::Float64, L::Float64, N_t::Int, t_max::Float64, t_min::Float64, Δt::Float64, x_σ::Float64, x_μ::Float64)\n\nCreate a struct to hold parameters for spectral physics loss.\n\nFields\n\nν: Viscosity (scalar)\nL: Domain size (scalar)\nN_t: Number of time steps (integer)\nt_max: Maximum time (scalar)\nt_min: Minimum time (scalar)\nΔt: Time step size (scalar)\nx_σ: Standard deviation for normalization (scalar)\nx_μ: Mean for normalization (scalar)\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.add_noise-Tuple{AbstractArray}","page":"Reference","title":"ESM_PINO.add_noise","text":"add_noise(data::AbstractArray; noise_level::Real=0.1, noise_type::Symbol=:gaussian, relative::Bool=true, rng::AbstractRNG=Random.GLOBAL_RNG)\n\nAdd random noise to an array, supporting Gaussian or uniform distributions.\n\nArguments\n\ndata::AbstractArray: Input array to which noise will be added.\nnoise_level::Real=0.1: Magnitude of the noise. Interpreted as standard deviation for Gaussian or half-width for uniform.\nnoise_type::Symbol=:gaussian: Type of noise distribution. Options: :gaussian or :uniform.\nrelative::Bool=true: If true, scale the noise level relative to the standard deviation of data.\nrng::AbstractRNG=Random.GLOBAL_RNG: Random number generator.\n\nReturns\n\nArray: A copy of data with added noise.\n\nDetails\n\nFor :gaussian noise, samples are drawn from a normal distribution with mean 0 and specified standard deviation.\nFor :uniform noise, samples are drawn uniformly from [-noise_level, noise_level].\nIf relative=true, the noise magnitude is scaled by the standard deviation of data.\n\nExample\n\njulia> x = rand(10);\n\njulia> y = add_noise(x; noise_level=0.05, noise_type=:gaussian);\n\njulia> z = add_noise(x; noise_level=0.2, noise_type=:uniform, relative=false);\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.apply_pattern-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractArray{T}}} where {T, N}","page":"Reference","title":"ESM_PINO.apply_pattern","text":"apply_pattern(x_tr::AbstractArray{T,N}, weights::AbstractArray{T,3}) where {T,N}\n\nApply learned weight patterns to truncated Fourier coefficients.\n\nArguments\n\nx_tr::AbstractArray{T,N}: Truncated Fourier coefficients after low-pass filtering, with shape (modes..., in_channels, batch)\nweights::AbstractArray{T,4}: Complex-valued learned weights with shape (modes..., outchannels, inchannels)\n\nReturns\n\nWeighted Fourier coefficients with shape (modes..., out_channels, batch)\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.autoregressive_loss-Tuple{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer, Tuple{AbstractArray, AbstractArray}, Int64, ESM_PINO.FDPhysicsLossParameters, Float32}","page":"Reference","title":"ESM_PINO.autoregressive_loss","text":"autoregressive_loss(model::StatefulLuxLayer, (u0, target)::Tuple{AbstractArray, AbstractArray}, n_steps::Int, params::FDPhysicsLossParameters, λ::Float32)\n\nCompute autoregressive loss for a model over multiple time steps.\n\nArguments\n\nmodel: StatefulLuxLayer model\nu0: Initial state (input data)\ntarget: Target data for comparison\nn_steps: Number of time steps to propagate\nparams: FDPhysicsLossParameters struct containing physics parameters\nλ: Weighting factor for physics loss\n\nReturns\n\nTotal loss combining data loss and physics-informed loss\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.compute_k-Union{Tuple{T}, Tuple{AbstractArray{T}, T}} where T<:Real","page":"Reference","title":"ESM_PINO.compute_k","text":"compute_k(u::AbstractArray{T}, L::T) where T<:Real\n\nGenerate wavenumber array for spectral differentiation.\n\nArguments\n\nu: Template array for dimensions\nL: Domain length\n\nReturns\n\nk: Wavenumber array on GPU, reshaped for broadcasting\n\nDetails\n\nHandles even/odd array sizes differently\nAutomatically converts to GPU array\nReturns array with singleton dimensions for ND broadcasting\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.create_physics_loss-Tuple{ESM_PINO.SpectralPhysicsLossParameters}","page":"Reference","title":"ESM_PINO.create_physics_loss","text":"create_physics_loss()\n\nhelper function to create a physics loss function.\n\nArguments\n\nparams: parameters struct, pass nothing to create a zero loss function.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.dealias-Union{Tuple{T}, Tuple{AbstractArray{Complex{T}}, T}} where T<:Real","page":"Reference","title":"ESM_PINO.dealias","text":"dealias(u_hat::AbstractArray{Complex{T}}, L::T) where T<:Real\n\nApply 2/3 dealiasing filter to Fourier coefficients.\n\nArguments\n\nu_hat: Fourier coefficients (complex array)\nL: Domain length (unused in current implementation)\n\nReturns\n\nFiltered coefficients with high frequencies zeroed\n\nNotes\n\nImplements 2/3 rule for anti-aliasing\nCreates mask directly on GPU\nPreserves array dimensions for broadcasting\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.expand_pad_dims-Union{Tuple{NTuple{N, Int64}}, Tuple{N}} where N","page":"Reference","title":"ESM_PINO.expand_pad_dims","text":"expand_pad_dims(pad_dims::Dims{N}) where {N}\n\nConvert N-dimensional padding specification into format required for NNlib's pad_constant function.\n\nArguments\n\npad_dims::Dims{N}: Tuple of N integers specifying the total padding needed along each dimension\n\nReturns\n\nNTuple{2N,Int}: Tuple of 2N integers specifying padding for both sides of each dimension, where padding is applied only at the end of each dimension (start padding is always 0)\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.low_pass-Tuple{AbstractArray, Any}","page":"Reference","title":"ESM_PINO.low_pass","text":"low_pass(x_ft, modes)\n\nApply a low-pass filter to a Fourier-transformed array by retaining only the lowest frequency modes.\n\nArguments\n\nx_ft: A Fourier-transformed array with at least 2 trailing dimensions\nmodes: A tuple or array specifying the number of low-frequency modes to keep along each leading dimension\n\nReturns\n\nA view of the input array x_ft containing only the specified low-frequency modes, preserving the last two dimensions in full\n\nDetails\n\nThe function creates a view that selects the first modes[i] elements along each leading dimension i, while keeping all elements of the last two dimensions. This effectively implements a low-pass filter in Fourier space by truncating high-frequency modes.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.meshgrid-Tuple{Any, Any}","page":"Reference","title":"ESM_PINO.meshgrid","text":"meshgrid(x, y)\n\nGenerates a 2D meshgrid from vectors x and y.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.mse_loss_function-Tuple{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer, AbstractArray, AbstractArray}","page":"Reference","title":"ESM_PINO.mse_loss_function","text":"mse_loss_function(u::StatefulLuxLayer, target::AbstractArray, xt::AbstractArray)\n\nStandard mean squared error loss.\n\nArguments\n\nu: Neural network\ntarget: Ground truth values\nu_t1: Network inputs\n\nReturns\n\nMSE between network output and target\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.normalize_data-Tuple{Any}","page":"Reference","title":"ESM_PINO.normalize_data","text":"normalize_data(data)\n\nNormalize an array to zero mean and unit variance. #Arguments -data: Input array. #Returns -(normalized_data, μ, σ): A tuple containing:     normalized_data: The normalized array.     μ: The mean of the original data.     σ: The standard deviation of the original data.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.select_loss_function","page":"Reference","title":"ESM_PINO.select_loss_function","text":"select_loss_function()\n\nHelper function to pass a valid loss function to Training.singletrainstep. Selects a loss function based on the provided physics-informed loss function, in the standard workflow generated with createphysicsloss.\n\nArguments\n\nPI_loss: Physics-informed loss function (default is a zero loss function)\n\n\n\n\n\n","category":"function"},{"location":"ref/#ESM_PINO.spectral_derivative-Union{Tuple{T}, Tuple{AbstractArray{T}, T}} where T<:Real","page":"Reference","title":"ESM_PINO.spectral_derivative","text":"spectral_derivative(u::AbstractArray{T}, L::T) where T<:Real\n\nCompute first and second spatial derivatives using FFT spectral methods.\n\nArguments\n\nu: Input array (real-valued), assumed to be on GPU. First dimension is spatial.\nL: Domain length in spatial dimension.\n\nReturns\n\ndu: First derivative (real array)\nd2u: Second derivative (real array)\n\nNotes\n\nUses FFT/iFFT with wavenumbers from compute_k\nAssumes periodic boundary conditions\nMaintains input array type/location (GPU/CPU)\nOutput derivatives are real-valued arrays\n\n\n\n\n\n","category":"method"},{"location":"#ESM_PINO","page":"Home","title":"ESM_PINO","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ESM_PINO.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The SFNO components are empty-defined in the main module and work through extensions by loading two different backends for the Spherical Harmonics transforms: QG3.jl (supports Zygote for automatic differentiation), and SpeedyWeather.jl (still work in progress)","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
