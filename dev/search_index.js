var documenterSearchIndex = {"docs":
[{"location":"extensions/QG3/#QG3-Extension","page":"QG3 Extension","title":"QG3 Extension","text":"","category":"section"},{"location":"extensions/QG3/","page":"QG3 Extension","title":"QG3 Extension","text":"This page documents the QG3-based SFNO layers","category":"page"},{"location":"extensions/QG3/#ESM_PINO.SFNO-Tuple{QG3.GaussianGridtoSHTransform, QG3.SHtoGaussianGridTransform}","page":"QG3 Extension","title":"ESM_PINO.SFNO","text":"SFNO(\n    ggsh::QG3.GaussianGridtoSHTransform,\n    shgg::QG3.SHtoGaussianGridTransform;\n    modes,\n    in_channels,\n    out_channels,\n    hidden_channels,\n    n_layers,\n    lifting_channel_ratio,\n    projection_channel_ratio,\n    channel_mlp_expansion,\n    activation,\n    positional_embedding,\n    inner_skip,\n    outer_skip,\n    zsk\n) -> SFNO{__T_nrepeats, Static.False, ESM_PINOQG3Ext.ESM_PINOQG3} where __T_nrepeats<:Static.StaticInt\n\n\nSpherical Fourier Neural Operator (SFNO) layer combining positional embeddings, spectral kernels, and channel MLPs.\n\nThis layer implements the SFNO architecture on the sphere, optionally using Zonal Symmetric Kernels (ZSK) following the approach described in Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere.\n\nArguments\n\nggsh::QG3.GaussianGridtoSHTransform: Precomputed grid-to-SH transform.\nshgg::QG3.SHtoGaussianGridTransform: Precomputed SH-to-grid transform.\nOther keyword arguments are the same as for the primary constructor, except modes which default is set to ggsh.output_size[1]. Also, no need to specify batch_size or gpu as these are handled in the transforms.\n\nReturns\n\nSFNO: A Lux-compatible container layer.\n\nDetails\n\nConstructs lifting, SFNO blocks, and projection layers compatible with Lux.jl.\nPositional embeddings are appended if positional_embedding=\"grid\".\nSupports both CPU and GPU execution.\nZonal Symmetric Kernels (ZSK) reduce the number of parameters and improve stability on spherical domains.\n\nExample\n\nusing Lux, QG3, Random, NNlib, LuxCUDA\n\n# Load precomputed QG3 parameters\nqg3ppars = QG3.load_precomputed_params()[2]\n\n# Input: [lat, lon, channels, batch]\nx = rand(Float32, 32, 64, 3, 10)\n\n\n# Construct SFNO layer using secondary constructor\nggsh = QG3.GaussianGridtoSHTransform(qg3ppars, 32, N_batch=size(x,4))\nshgg = QG3.SHtoGaussianGridTransform(qg3ppars, 32, N_batch=size(x,4))\nmodel2 = SFNO(ggsh, shgg;\n    modes=15,\n    in_channels=3,\n    out_channels=3,\n    hidden_channels=32,\n    n_layers=4,\n    lifting_channel_ratio=2,\n    projection_channel_ratio=2,\n    channel_mlp_expansion=2.0,\n    positional_embedding=\"no_grid\",\n    outer_skip=true,\n    zsk=true\n)\n\n# Setup parameters and state\nrng = Random.default_rng(0)\nps, st = Lux.setup(rng, model2)\n\n# Forward pass\ny, st = model2(x, ps, st)\n\n# Compute gradients\nusing Zygote\ngr = Zygote.gradient(ps -> sum(model2(x, ps, st)[1]), ps)\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINO.SFNO-Tuple{QG3ModelParameters}","page":"QG3 Extension","title":"ESM_PINO.SFNO","text":"SFNO(\n    pars::QG3ModelParameters;\n    batch_size,\n    modes,\n    in_channels,\n    out_channels,\n    hidden_channels,\n    n_layers,\n    lifting_channel_ratio,\n    projection_channel_ratio,\n    channel_mlp_expansion,\n    activation,\n    positional_embedding,\n    inner_skip,\n    outer_skip,\n    gpu,\n    zsk\n) -> SFNO{__T_nrepeats, Static.False, ESM_PINOQG3Ext.ESM_PINOQG3} where __T_nrepeats<:Static.StaticInt\n\n\nSpherical Fourier Neural Operator (SFNO) layer combining positional embeddings, spectral kernels, and channel MLPs.\n\nThis layer implements the SFNO architecture on the sphere, optionally using Zonal Symmetric Kernels (ZSK) following the approach described in Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere.\n\nArguments\n\npars::QG3ModelParameters: Model parameters defining the spherical grid and maximum spherical harmonic degree L.\nbatch_size::Int=1: Number of samples in a batch.\nmodes::Int=pars.L: Maximum number of spherical harmonic modes to use.\nin_channels::Int: Number of input channels.\nout_channels::Int: Number of output channels.\nhidden_channels::Int=32: Number of hidden channels in the SFNO blocks.\nn_layers::Int=4: Number of SFNO blocks.\nlifting_channel_ratio::Int=2: Expansion ratio for the lifting layer.\nprojection_channel_ratio::Int=2: Expansion ratio for the projection layer.\nchannel_mlp_expansion::Number=2.0: Expansion factor for channel MLPs in each SFNO block.\nactivation: Activation function (default is NNlib.gelu).\npositional_embedding::AbstractString=\"grid\": Type of positional embedding. Options: \"grid\" or \"no_grid\".\ninner_skip::Bool=true: If true, use skip connections inside each SFNO block.\nouter_skip::Bool=true: If true, apply residual connection from lifting output to projection output.\ngpu::Bool=true: If true, computations are performed on GPU.\nzsk::Bool=false: If true, use Zonal Symmetric Kernels, enforcing longitudinal symmetry.\n\nReturns\n\nSFNO: A Lux-compatible container layer.\n\nDetails\n\nConstructs lifting, SFNO blocks, and projection layers compatible with Lux.jl.\nPositional embeddings are appended if positional_embedding=\"grid\".\nSupports both CPU and GPU execution.\nZonal Symmetric Kernels (ZSK) reduce the number of parameters and improve stability on spherical domains.\n\nExample\n\nusing Lux, QG3, Random, NNlib, LuxCUDA\n\n# Load precomputed QG3 parameters\nqg3ppars = QG3.load_precomputed_params()[2]\n\n# Input: [lat, lon, channels, batch]\nx = rand(Float32, 32, 64, 3, 10)\n\n# Construct SFNO layer using primary constructor\nmodel1 = SFNO(qg3ppars;\n    batch_size=size(x, 4),\n    modes=30,\n    in_channels=3,\n    out_channels=3,\n    hidden_channels=32,\n    n_layers=4,\n    lifting_channel_ratio=2,\n    projection_channel_ratio=2,\n    channel_mlp_expansion=2.0,\n    positional_embedding=\"no_grid\",\n    outer_skip=true,\n    gpu=false\n)\n\n\n# Setup parameters and state\nrng = Random.default_rng(0)\nps, st = Lux.setup(rng, model1)\n\n# Forward pass\ny, st = model1(x, ps, st)\n\n# Compute gradients\nusing Zygote\ngr = Zygote.gradient(ps -> sum(model1(x, ps, st)[1]), ps)\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINO.SFNO_Block-Tuple{Int64, QG3.GaussianGridtoSHTransform, QG3.SHtoGaussianGridTransform}","page":"QG3 Extension","title":"ESM_PINO.SFNO_Block","text":"SFNO_Block(\n    channels::Int64,\n    ggsh::QG3.GaussianGridtoSHTransform,\n    shgg::QG3.SHtoGaussianGridTransform;\n    modes,\n    expansion_factor,\n    activation,\n    skip,\n    zsk\n) -> ESM_PINO.SFNO_Block{ESM_PINOQG3Ext.ESM_PINOQG3}\n\n\nA block that combines a spherical kernel with a channel MLP. Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nchannels::Int: Number of input/output channels\nggsh::GaussianGridtoSHTransform: Transformation from Gaussian grid to spherical harmonics\nshgg::SHtoGaussianGridTransform: Transformation from spherical harmonics back to Gaussian\nmodes::Int=ggsh.output_size[1]: Number of spherical harmonic modes to retain (default: ggsh.output_size[1])\nexpansion_factor::Real=2.0: Expansion factor for the ChannelMLP (default: 2.0)\nactivation: Activation function applied after combining spatial and spectral branches (default: NNlib.gelu)\nskip::Bool=true: Whether to include a skip connection (default: true)\nzsk::Bool=false: Whether to use Zonal Symmetric Kernels (ZSK) (default: false)\n\nReturns\n\nSFNO_Block: A Lux-compatible layer operating on 4D arrays [lat, lon, channels, batch].\n\nFields\n\nspherical_kernel::SphericalKernel: Spherical kernel layer\nchannel_mlp::ChannelMLP: Channel-wise MLP layer\nchannels::Int: Number of input/output channels\nskip::Bool: Whether to include a skip connection\n\nDetails\n\nThe input is processed by a SphericalKernel followed by a ChannelMLP\nIf skip is true, the input is added to the output (residual connection)\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINO.SFNO_Block-Tuple{Int64, QG3ModelParameters}","page":"QG3 Extension","title":"ESM_PINO.SFNO_Block","text":"SFNO_Block(\n    channels::Int64,\n    pars::QG3ModelParameters;\n    modes,\n    batch_size,\n    expansion_factor,\n    activation,\n    skip,\n    gpu,\n    zsk\n) -> ESM_PINO.SFNO_Block{ESM_PINOQG3Ext.ESM_PINOQG3}\n\n\nA block that combines a spherical kernel with a channel MLP. Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nchannels::Int: Number of input/output channels\npars::QG3ModelParameters: Precomputed QG3 model parameters (QG3ModelParameters)\nmodes::Int=pars.L: Number of spherical harmonic modes to retain (default: pars.L)\nbatch_size::Int=1: Batch size for transforms (default: 1)\nexpansion_factor::Real=2.0: Expansion factor for the ChannelMLP (default: 2.0)\nactivation: Activation function applied after combining spatial and spectral branches (default: NNlib.gelu)\nskip::Bool=true: Whether to include a skip connection (default: true)\ngpu::Bool=true: Whether to use GPU (default: true)\nzsk::Bool=false: Whether to use Zonal Symmetric Kernels (ZSK) (default: false)\n\nReturns\n\nSFNO_Block: A Lux-compatible layer operating on 4D arrays [lat, lon, channels, batch].\n\nFields\n\nspherical_kernel::SphericalKernel: Spherical kernel layer\nchannel_mlp::ChannelMLP: Channel-wise MLP layer\nchannels::Int: Number of input/output channels\nskip::Bool: Whether to include a skip connection\n\nDetails\n\nThe input is processed by a SphericalKernel followed by a ChannelMLP\nIf skip is true, the input is added to the output (residual connection)\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINO.SphericalConv","page":"QG3 Extension","title":"ESM_PINO.SphericalConv","text":"SphericalConv(\n    hidden_channels::Int64,\n    ggsh::QG3.GaussianGridtoSHTransform,\n    shgg::QG3.SHtoGaussianGridTransform;\n    ...\n) -> ESM_PINO.SphericalConv{ESM_PINOQG3Ext.ESM_PINOQG3}\nSphericalConv(\n    hidden_channels::Int64,\n    ggsh::QG3.GaussianGridtoSHTransform,\n    shgg::QG3.SHtoGaussianGridTransform,\n    modes::Int64;\n    zsk\n) -> ESM_PINO.SphericalConv{ESM_PINOQG3Ext.ESM_PINOQG3}\n\n\nSpherical convolution layer for functions on the sphere using spherical harmonics.   Transforms data from Gaussian grid → spherical harmonics, applies learned weights, and transforms back.\n\nArguments\n\nhidden_channels::Int: Number of input/output channels.\nggsh::GaussianGridtoSHTransform: Transformation from Gaussian grid to spherical harmonics.\nshgg::SHtoGaussianGridTransform: Transformation from spherical harmonics back to Gaussian grid.\nmodes::Int=ggsh.output_size[1]: Maximum number of spherical harmonic modes to use. If higher than ggsh.output_size[1], it is truncated with a warning.\nzsk::Bool=false: If true, uses Zonal Symmetric Kernels (ZSK), reducing the number of free weights. It follows Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere.\n\nReturns\n\nSphericalConv: A Lux-compatible layer operating on 4D arrays [lat, lon, channels, batch].\n\nDetails\n\nInput is permuted internally to [channels, lat, lon, batch] for computation.\nUses ps.weight for element-wise multiplication in spherical harmonic space.\nSupports padding to match the original spherical grid dimensions.\nCompatible with GPU and CPU (controlled externally in ggsh, shgg constructor).\n\nExample\n\nusing Random, Lux, QG3, NNlib\n\n# Load precomputed spherical model parameters\nqg3ppars = QG3.load_precomputed_params()[2]\n\n# Create transforms\nggsh = QG3.GaussianGridtoSHTransform(qg3ppars, 32, N_batch=1)\nshgg = QG3.SHtoGaussianGridTransform(qg3ppars, 32, N_batch=1)\n\n# Initialize layer\nlayer = SphericalConv(32, ggsh, shgg, 30; zsk=true)\n\n# Generate random input [lat, lon, channels, batch]\nx = rand(Float32, 32, 64, 32, 1)\n\n# Setup parameters and state\nrng = Random.default_rng(0)\nps, st = Lux.setup(rng, layer)\n\n# Forward pass\ny, st = layer(x, ps, st)\n\n# Compute gradient\nusing Zygote\ngr = Zygote.gradient(ps -> sum(layer(x, ps, st)[1]), ps)\n\n\n\n\n\n","category":"type"},{"location":"extensions/QG3/#ESM_PINO.SphericalConv-Union{Tuple{T}, Tuple{QG3ModelParameters{T, I, A, M} where {I<:Int64, A<:AbstractVector{T}, M<:AbstractMatrix{T}}, Int64}} where T","page":"QG3 Extension","title":"ESM_PINO.SphericalConv","text":"SphericalConv(\n    pars::QG3ModelParameters{T, I, A, M} where {I<:Int64, A<:AbstractArray{T, 1}, M<:AbstractArray{T, 2}},\n    hidden_channels::Int64;\n    modes,\n    batch_size,\n    gpu,\n    zsk\n) -> ESM_PINO.SphericalConv{ESM_PINOQG3Ext.ESM_PINOQG3}\n\n\nConstruct a spherical convolution layer using precomputed model parameters.\n\nArguments\n\npars::QG3.QG3ModelParameters{T}: Model parameters defining the spherical grid resolution and maximum spherical harmonic degree L.\nhidden_channels::Int: Number of input/output channels.\nmodes::Int=pars.L: Maximum number of spherical harmonic modes to use. If higher than pars.L, it is truncated with a warning.\nbatch_size::Int=1: Number of samples in a batch (used for internal transforms).\ngpu::Bool=true: If true, computations are moved to GPU using QG3.gpuon().\nzsk::Bool=false: If true, uses Zonal Symmetric Kernels (ZSK), reducing the number of free weights. ZSK enforces rotational symmetry along longitude and follows Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere.\n\nReturns\n\nSphericalConv: A Lux-compatible layer operating on 4D arrays [lat, lon, channels, batch].\n\nDetails\n\nInternally constructs GaussianGridtoSHTransform and SHtoGaussianGridTransform objects for the given pars and hidden_channels.\nCorrects the requested modes to not exceed pars.L.\nSupports both CPU and GPU computation.\nZonal Symmetric Kernels (ZSK) reduce the number of learnable parameters by enforcing symmetry along longitude, improving stability for spherical dynamics.\n\nExample\n\nusing Random, Lux, QG3, NNlib\n\n# Load precomputed parameters\nqg3ppars = QG3.load_precomputed_params()[2]\n\n# Initialize spherical convolution layer\nlayer = SphericalConv(qg3ppars, 32; modes=30, batch_size=1, gpu=false, zsk=true)\n\n# Generate random input [lat, lon, channels, batch]\nx = rand(Float32, 64, 128, 32, 1)\n\n# Setup parameters and state\nrng = Random.default_rng(0)\nps, st = Lux.setup(rng, layer)\n\n# Forward pass\ny, st = layer(x, ps, st)\n\n# Compute gradient\nusing Zygote\ngr = Zygote.gradient(ps -> sum(layer(x, ps, st)[1]), ps)\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINO.SphericalKernel","page":"QG3 Extension","title":"ESM_PINO.SphericalKernel","text":"SphericalKernel(\n    hidden_channels::Int64,\n    ggsh::QG3.GaussianGridtoSHTransform,\n    shgg::QG3.SHtoGaussianGridTransform;\n    ...\n) -> ESM_PINO.SphericalKernel{ESM_PINOQG3Ext.ESM_PINOQG3}\nSphericalKernel(\n    hidden_channels::Int64,\n    ggsh::QG3.GaussianGridtoSHTransform,\n    shgg::QG3.SHtoGaussianGridTransform,\n    activation;\n    modes,\n    zsk\n) -> ESM_PINO.SphericalKernel{ESM_PINOQG3Ext.ESM_PINOQG3}\n\n\nConstruct a SphericalKernel layer using precomputed transforms.\n\nArguments\n\nhidden_channels::Int: Number of channels\nggsh::GaussianGridtoSHTransform: Transformation from Gaussian grid to spherical harmonics\nshgg::SHtoGaussianGridTransform: Transformation from spherical harmonics back to Gaussian grid\nactivation: Activation function applied after combining spatial and spectral branches (default: NNlib.gelu)\nmodes::Int=ggsh.output_size[1]: Number of spherical harmonic modes to retain (default: ggsh.output_size[1])\nzsk::Bool=false: Whether to use Zonal Symmetric Kernels (ZSK) (default: false)\n\nReturns\n\nSphericalKernel: A Lux-compatible layer operating on 4D arrays [lat, lon, channels, batch].\n\nFields\n\nspatial_conv::P: 1x1 convolution operating directly in the spatial domain\nspherical_conv::SphericalalConv: Spherical convolution layer\nactivation::F: Elementwise activation function\n\n\n\n\n\n","category":"type"},{"location":"extensions/QG3/#ESM_PINO.SphericalKernel-2","page":"QG3 Extension","title":"ESM_PINO.SphericalKernel","text":"SphericalKernel(\n    hidden_channels::Int64,\n    pars::QG3ModelParameters;\n    ...\n) -> ESM_PINO.SphericalKernel{ESM_PINOQG3Ext.ESM_PINOQG3}\nSphericalKernel(\n    hidden_channels::Int64,\n    pars::QG3ModelParameters,\n    activation;\n    modes,\n    batch_size,\n    gpu,\n    zsk\n) -> ESM_PINO.SphericalKernel{ESM_PINOQG3Ext.ESM_PINOQG3}\n\n\nCombines a SphericalConv layer with a 1x1 convolution in parallel, followed by an activation function. Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nhidden_channels: Number of channels\npars: Precomputed QG3 model parameters (QG3ModelParameters)\nactivation: Activation function applied after combining spatial and spectral branches (default: NNlib.gelu)\nmodes: Number of spherical harmonic modes to retain (default: pars.L)\nbatch_size: Batch size for transforms (default: 1)\ngpu: Whether to use GPU (default: true)\nzsk: Whether to use Zonal Symmetric Kernels (ZSK) (default: false)\n\n#Returns\n\nSphericalKernel: A Lux-compatible layer operating on 4D arrays `[lat,\n\nFields\n\nspatial_conv::P: 1x1 convolution operating directly in the spatial domain\nspherical_conv::SphericalalConv: Spherical convolution layer\nactivation::F: Elementwise activation function\n\nDetails\n\nThe input is processed in parallel by a 1x1 convolution and a spherical convolution\nOutputs from both branches are summed and passed through the activation\nUseful for mixing local (spatial) and global (spectral) information\n\n\n\n\n\n","category":"type"},{"location":"extensions/QG3/#ESM_PINOQG3Ext.QG3_Physics_Parameters","page":"QG3 Extension","title":"ESM_PINOQG3Ext.QG3_Physics_Parameters","text":"QG3_Physics_Parameters(dt::Float64, rhs::AbstractArray)\n\nCreate a struct to hold parameters for QG3 physics loss.\n\nFields\n\ndt: Time step (scalar)\nrhs: Right-hand side of the QG3 equation (array)\n\n\n\n\n\n","category":"type"},{"location":"extensions/QG3/#ESM_PINOQG3Ext.QG3_loss_function-Tuple{LuxCore.AbstractLuxLayer, NamedTuple, NamedTuple, Tuple{AbstractArray, AbstractArray}}","page":"QG3 Extension","title":"ESM_PINOQG3Ext.QG3_loss_function","text":"QG3_loss_function(model, ps, st, (u_t1, target_data); α=0.5f0)\n\nCombined physics-data loss function for QG3.\n\nArguments\n\nmodel: Lux model\nps: Model parameters\nst: Model state\nu_t1: Input data\ntarget_data: Training targets\nα: Loss weighting (0.5 = equal weighting)\n\nReturns\n\nTuple containing:\nTotal loss\nUpdated state\nNamed tuple with loss components (physicsloss, dataloss)\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINOQG3Ext.create_QG3_physics_loss-Tuple{ESM_PINOQG3Ext.QG3_Physics_Parameters}","page":"QG3 Extension","title":"ESM_PINOQG3Ext.create_QG3_physics_loss","text":"create_QG3_physics_loss()\n\nHelper function to create a QG3 physics loss function.\n\nArguments\n\nparams: parameters struct, pass nothing to create a zero loss function.\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINOQG3Ext.physics_informed_loss_QG3-Tuple{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer, AbstractArray}","page":"QG3 Extension","title":"ESM_PINOQG3Ext.physics_informed_loss_QG3","text":"physics_informed_loss_QG3(u::StatefulLuxLayer, q_0::AbstractArray)\n\nCompute residual loss for QG3 equation.\n\nArguments\n\nu: Neural network (StatefulLuxLayer)\nq_0: Initial state (input data)\n\nReturns\n\nResidual loss (mean squared residual)\n\nRequirements\n\nPrecomputed right-hand side rhs (global variable) computed using QG3.QG3MM_gpu\nPrecomputed time step dt (global variable) in QG3 units\n\n\n\n\n\n","category":"method"},{"location":"extensions/QG3/#ESM_PINOQG3Ext.select_QG3_loss_function","page":"QG3 Extension","title":"ESM_PINOQG3Ext.select_QG3_loss_function","text":"select_QG3_loss_function(PI_loss::Function=create_QG3_physics_loss(nothing); SFNO::Bool=false)\n\nHelper function to pass a valid QG3 loss function to Training.singletrainstep. Selects a loss function based on the provided physics-informed loss function, in the standard workflow generated with createQG3physics_loss.\n\nArguments\n\nPI_loss: Physics-informed loss function (default is a zero loss function)\n\n\n\n\n\n","category":"function"},{"location":"extensions/QG3/#ESM_PINOQG3Ext.transfer_SFNO_model-Tuple{Any, Any}","page":"QG3 Extension","title":"ESM_PINOQG3Ext.transfer_SFNO_model","text":"transfer_SFNO_model(model, qg3ppars; batch_size=default_batch_size)\n\nConstruct a new SFNO model with the same architecture/parameters as model, but adapted to new  discretization (qg3ppars) and batch size. Preserves spectral modes, channels, and other  hyperparameters from the original model.\n\nArguments\n\nmodel::SFNO: Source model whose architecture/hyperparameters will be copied.\nqg3ppars: New problem parameters (e.g., grid resolution) for the target model.\n\nKeywords\n\nbatch_size::Int: (optional) Desired batch size. Defaults to the original model's batch size  (extracted from model.sfno_blocks...FT_4d.plan.input_size[4]).\n\nReturns\n\nsuperres_model::SFNO: New model configured for the target specifications.\n\nExample\n\n# Original model (batch_size=32)\nmodel = SFNO(orig_pars, batch_size=32, ...)\n\n# Train model\nps, st = ...\n\n# Adapted model (batch_size=64, new grid params)\nnew_model = transfer_SFNO_model(model, new_pars; batch_size=64)\n\n# Perform inference using learned parameters\noutput = new_model(x, ps, st)\n\n\n\n\n\n","category":"method"},{"location":"extensions/SpeedyWeather/#Speedy-Weather-Extension","page":"Speedy Weather Extension","title":"Speedy Weather Extension","text":"","category":"section"},{"location":"extensions/SpeedyWeather/","page":"Speedy Weather Extension","title":"Speedy Weather Extension","text":"This page documents the SpeedyWeather-based SFNO layers","category":"page"},{"location":"extensions/SpeedyWeather/#ESM_PINOSpeedyWeatherExt.GaussianGridInfo","page":"Speedy Weather Extension","title":"ESM_PINOSpeedyWeatherExt.GaussianGridInfo","text":"GaussianGridInfo\n\nStructure containing information about a Gaussian grid resolution.\n\nFields\n\ntruncation::Int: Spectral truncation number (e.g., 31 for T31)\nnlat::Int: Number of latitude points\nnlon::Int: Number of longitude points  \nkm_at_equator::Float64: Approximate grid spacing at equator in km\ndeg_at_equator::Float64: Approximate grid spacing at equator in degrees\ndescription::String: Human-readable description\n\n\n\n\n\n","category":"type"},{"location":"extensions/SpeedyWeather/#ESM_PINOSpeedyWeatherExt.calculate_gaussian_grid_size-Tuple{Int64}","page":"Speedy Weather Extension","title":"ESM_PINOSpeedyWeatherExt.calculate_gaussian_grid_size","text":"calculate_gaussian_grid_size(truncation::Int) -> Tuple{Int, Int}\n\nCalculate Gaussian grid dimensions from spectral truncation number using standard formulas.\n\nFor a spectral truncation T, the standard relationships are:\n\nnlat = (truncation + 1) * 3 / 2  (for reduced grids, varies slightly)\nnlon = 2 * nlat  (for regular grids)\n\nArguments\n\ntruncation::Int: Spectral truncation number\n\nReturns\n\nTuple{Int, Int}: (nlat, nlon)\n\n\n\n\n\n","category":"method"},{"location":"extensions/SpeedyWeather/#ESM_PINOSpeedyWeatherExt.gaussian_resolution_to_grid-Tuple{AbstractString}","page":"Speedy Weather Extension","title":"ESM_PINOSpeedyWeatherExt.gaussian_resolution_to_grid","text":"gaussian_resolution_to_grid(resolution::AbstractString) -> Tuple{Int, Int}\n\nConvert a Gaussian grid resolution string (e.g., \"T31\", \"T63\") to (nlat, nlon) tuple.\n\nArguments\n\nresolution::AbstractString: Grid resolution in format \"TN\" where N is truncation number\n\nReturns\n\nTuple{Int, Int}: (number of latitude points, number of longitude points)\n\nExamples\n\njulia> gaussian_resolution_to_grid(\"T31\")\n(48, 96)\n\njulia> gaussian_resolution_to_grid(\"T63\")  \n(96, 192)\n\njulia> gaussian_resolution_to_grid(\"T255\")\n(256, 512)\n\nThrows\n\nArgumentError: If resolution is not recognized\n\n\n\n\n\n","category":"method"},{"location":"ref/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"ref/#ESM_PINO.AbstractSphericalConv","page":"Reference","title":"ESM_PINO.AbstractSphericalConv","text":"AbstractSphericalConv <: Lux.AbstractLuxLayer\n\nAbstract supertype for spherical convolution layers.\n\nConcrete implementations are provided by extensions:\n\nESM_PINOQG3Ext.SphericalConv: QG3-based transforms.\nESM_PINOSpeedyWeatherExt.SphericalConv: SpeedyWeather transforms.\n\nLoad the corresponding extension to use a specific implementation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.BurgersFD","page":"Reference","title":"ESM_PINO.BurgersFD","text":"BurgersFD{T}\n\nFinite-difference matrices for discretising the 1D Burgers equation using periodic boundary conditions.\n\nInitialization\n\nBurgersFD(T, n, Δx=1)   BurgersFD(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Second-derivative (Laplacian) matrix with periodic BCs\nM2::AbstractMatrix{T}: First-derivative (central differences) matrix with periodic BCs\n\nDetails\n\nM approximates ∂²/∂x² with periodic wrap-around.\nM2 approximates ∂/∂x using central differences and periodic wrap-around.\nUse these matrices for semi-discrete formulations of Burgers’ equation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.BurgersFD2","page":"Reference","title":"ESM_PINO.BurgersFD2","text":"BurgersFD2{T}\n\nFinite-difference matrices for the 1D Burgers equation with periodic boundary conditions using a backward-difference discretisation for the convective (first-derivative) term.\n\nInitialization\n\nBurgersFD2(T, n, Δx=1)   BurgersFD2(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Second-derivative (Laplacian) matrix with periodic BCs\nM2::AbstractMatrix{T}: First-derivative matrix using backward differences (periodic BCs)\n\nDetails\n\nM is identical in form to BurgersFD's Laplacian (periodic).\nM2 is a backward-difference approximation of ∂/∂x; can improve stability for convection-dominated flows.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.BurgersFD_Dirichlet","page":"Reference","title":"ESM_PINO.BurgersFD_Dirichlet","text":"BurgersFD_Dirichlet{T}\n\nFinite-difference matrices for the 1D Burgers equation with Dirichlet boundary conditions.\n\nInitialization\n\nBurgersFD_Dirichlet(T, n, Δx=1)   BurgersFD_Dirichlet(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Second-derivative matrix with Dirichlet enforcement at boundaries\nM2::AbstractMatrix{T}: First-derivative matrix with boundary rows/cols zeroed\n\nDetails\n\nBoundary rows/columns are zeroed to reflect fixed-value (Dirichlet) conditions.\nIntended for Burgers’ problems with fixed boundary values (e.g., u=0 at domain ends).\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.ChannelMLP","page":"Reference","title":"ESM_PINO.ChannelMLP","text":"ChannelMLP(channels::Int; expansion_factor=2.0, activation=gelu)\n\nImplements a channel-wise MLP with a skip connection.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\nchannels: Number of input/output channels\nexpansion_factor: Factor to expand hidden layer size (default: 2.0)\nactivation: Nonlinear activation function in hidden layer (default: NNlib.gelu)\n\nFields\n\nmlp::M: Two-layer Conv-based MLP with hidden dimension = expansion_factor * channels\nskip::S: Skip connection implemented as a SoftGating layer\nexpansion_factor::Number: Factor controlling hidden dimension size\n\nDetails\n\nExpands channels with a 1x1 convolution, applies nonlinearity, then projects back\nAdds gated skip connection to stabilize training\nFunctions similarly to a feed-forward block in transformers\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.ChannelMLP1D","page":"Reference","title":"ESM_PINO.ChannelMLP1D","text":"ChannelMLP1D(channels::Int; expansion_factor=0.5, activation=gelu)\n\nImplements a channel-wise MLP with a skip connection.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.ChannelMLP3D","page":"Reference","title":"ESM_PINO.ChannelMLP3D","text":"ChannelMLP3D(channels::Int; expansion_factor=0.5, activation=gelu)\n\nImplements a channel-wise MLP with a skip connection.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FDPhysicsLossParameters","page":"Reference","title":"ESM_PINO.FDPhysicsLossParameters","text":"FDPhysicsLossParameters(ν::Float64, N_t::Int, t_max::Float64, t_min::Float64, Δt::Float64, x_σ::Float64, x_μ::Float64, M1_gpu::AbstractArray, M2_gpu::AbstractArray)\n\nCreate a struct to hold parameters for finite difference physics loss.\n\nFields\n\nν: Viscosity (scalar)\n'tsteplength`: Time step length (scalar)\nM1_gpu: Second derivative FD matrix (GPU array)\nM2_gpu: First derivative FD matrix (GPU array)\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FNO_Block","page":"Reference","title":"ESM_PINO.FNO_Block","text":"FNO_Block(channels::Int, modes::NTuple{2,Int}; expansion_factor=2, activation=gelu)\n\nA block that combines a SpectralKernel with a ChannelMLP.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\nchannels: Number of input/output channels\nmodes: Tuple specifying number of low-frequency modes for the spectral convolution\nexpansion_factor: Factor controlling hidden dimension size in ChannelMLP (default: 2)\nactivation: Nonlinear activation function (default: NNlib.gelu)\n\nFields\n\nspectral_kernel::SpectralKernel: Combines spectral and spatial convolutions\nchannel_mlp::ChannelMLP: Channel-wise MLP with skip connection\nchannels::Int: Number of channels\nmodes::NTuple{2,Int}: Retained Fourier modes\n\nDetails\n\nApplies spectral kernel to mix global/local features\nFollows with a channel MLP for nonlinear channel mixing\nForms the core computational unit of a Fourier Neural Operator\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FNO_Block1D","page":"Reference","title":"ESM_PINO.FNO_Block1D","text":"FNO_Block1D\n\nA block that combines a spectral kernel with a channel MLP. \n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FNO_Block3D","page":"Reference","title":"ESM_PINO.FNO_Block3D","text":"FNO_Block3D\n\nA block that combines a spectral kernel with a channel MLP. \n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.FourierNeuralOperator","page":"Reference","title":"ESM_PINO.FourierNeuralOperator","text":"FourierNeuralOperator <: Lux.AbstractLuxContainerLayer\n\nA Fourier Neural Operator (FNO) container that optionally includes positional embeddings, lifting and projection convolutions, and a stack of FNO blocks.\n\nArguments\n\nin_channels::Int: Number of input channels.\nout_channels::Int: Number of output channels.\nhidden_channels::Int=32: Number of hidden channels used inside FNO blocks.\nn_modes::NTuple{N,Int}=(16, 16): Number of retained Fourier modes per spatial dimension.\nn_layers::Int=4: Number of FNO blocks to stack.\nlifting_channel_ratio::Int=2: Channel expansion ratio used in the lifting layer.\nprojection_channel_ratio::Int=2: Channel expansion ratio used in the projection layer.\nchannel_mlp_expansion::Number=2: Expansion factor inside ChannelMLP of each block.\nactivation=NNlib.gelu: Activation function used in conv layers.\npositional_embedding::AbstractString=\"grid\": Choice of positional embedding:\n\n\"grid\", \"nogrid\" => 2D variants (GridEmbedding2D or NoOpLayer) \"grid1D\", \"nogrid1D\" => 1D variants (GridEmbedding1D or NoOpLayer) \"grid3D\", \"no_grid3D\" => 3D variants (GridEmbedding3D or NoOpLayer)\n\nFields\n\nembedding: Positional embedding layer (a GridEmbeddingND or NoOpLayer).\nlifting: Lifting convolution(s) mapping inchannels -> hiddenchannels.\nfno_blocks: Repeated stack of FNO blocks appropriate to dimensionality.\nprojection: Projection convolution(s) mapping hiddenchannels -> outchannels.\n\nExamples\n\nExample (2D data with grid embedding):\n\nusing Lux, Random, NNlib\n\nrng = Random.default_rng()\n\nlayer = FourierNeuralOperator(\n    in_channels=3,\n    out_channels=2,\n    hidden_channels=32,\n    n_modes=(12, 12),\n    n_layers=4,\n    positional_embedding=\"grid\"\n)\n\nps = Lux.initialparameters(rng, layer)\nst = Lux.initialstates(rng, layer)\n\n# Input tensor (H, W, C, Batch)\nx = randn(Float32, 64, 64, 3, 10)\n\ny, st_new = layer(x, ps, st)\n@show size(y)   # expect (64, 64, 2, 10)\n\nExample (1D data without grid embedding):\n\nlayer1d = FourierNeuralOperator(\n    in_channels=1,\n    out_channels=1,\n    hidden_channels=16,\n    n_modes=(8,),\n    n_layers=3,\n    positional_embedding=\"no_grid1D\"\n)\n\nx1 = randn(Float32, 128, 1, 5)   # (L, C, Batch)\ny1, _ = layer1d(x1,\n    Lux.initialparameters(rng, layer1d),\n    Lux.initialstates(rng, layer1d)\n)\n@show size(y1)   # expect (128, 1, 5)\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.Grid","page":"Reference","title":"ESM_PINO.Grid","text":"Grid{T}\n\nDiscretization grid for 1D finite difference schemes.\n\nInitialization\n\nGrid(x)\n\nwith x an array or range with constant spacing.\n\nArguments\n\nx::AbstractVector{T}: Discretization points, assumed uniformly spaced.\n\nFields\n\nN::Int: Number of grid points\nx::AbstractVector{T}: Coordinates of grid points\nΔx::T: Grid spacing, computed from x\n\nDetails\n\nComputes Δx as the absolute difference between the first two grid points.\nUseful for constructing finite-difference scheme matrices.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.GridEmbedding2D","page":"Reference","title":"ESM_PINO.GridEmbedding2D","text":"GridEmbedding2D(grid_boundaries=[[0f0, 1f0], [0f0, 1f0]])\n\nPositional embedding that appends normalized 2D coordinates to the input.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\ngrid_boundaries: Vector of two intervals [x_min, x_max], [y_min, y_max] specifying coordinate range along each axis\n\nFields\n\nboundaries_x::Vector{Float32}: Range boundaries for x-coordinate\nboundaries_y::Vector{Float32}: Range boundaries for y-coordinate\n\nDetails\n\nConstructs a 2D meshgrid of coordinates normalized to [x_min, x_max] × [y_min, y_max]\nRepeats coordinate grids across batch dimension\nConcatenates grid_x and grid_y as extra channels to the input\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.GridEmbedding3D","page":"Reference","title":"ESM_PINO.GridEmbedding3D","text":"GridEmbedding3D(grid_boundaries=[[0f0, 1f0], [0f0, 1f0], [0f0, 1f0]])\n\nPositional embedding that appends a normalized 3D coordinate grid to input data.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.NeumannFD","page":"Reference","title":"ESM_PINO.NeumannFD","text":"NeumannFD{T}\n\nFinite-difference operator for the first derivative with Neumann boundary conditions (enforcing zero derivative at the boundaries).\n\nInitialization\n\nNeumannFD(T, n, Δx=1)   NeumannFD(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type (e.g. Float64, Float32)\nn::Integer: Number of grid points\nΔx::Number: Grid spacing (default: 1)\ngrid::Grid{T}: Grid object containing N and Δx\n\nFields\n\nM::AbstractMatrix{T}: Finite-difference matrix representing the derivative operator\n\nDetails\n\nImplements central differences for the interior and modifies boundary rows to enforce zero slope.\nThe returned operator approximates ∂/∂x with Neumann BCs.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.PeriodicFD","page":"Reference","title":"ESM_PINO.PeriodicFD","text":"PeriodicFD{T}\n\nFinite-difference operator for the first derivative with periodic boundary conditions.\n\nInitialization\n\nPeriodicFD(T, n, Δx=1)   PeriodicFD(grid::Grid{T})\n\nArguments\n\nT::DataType: Element type\nn::Integer: Number of grid points\nΔx::Number: Grid spacing (default: 1)\ngrid::Grid{T}: Grid object\n\nFields\n\nM::AbstractMatrix{T}: Finite-difference matrix representing the derivative operator\n\nDetails\n\nImplements central differences and wraps the stencil at the domain boundaries (periodic).\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SFNO","page":"Reference","title":"ESM_PINO.SFNO","text":"Empty layer to test extension documentation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SFNO_Block","page":"Reference","title":"ESM_PINO.SFNO_Block","text":"Empty layer to test extension documentation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SoftGating","page":"Reference","title":"ESM_PINO.SoftGating","text":"SoftGating(channels::Int)\n\nA soft gating layer that applies per-channel multiplicative scaling.   Expects input in (height, width, channels, batch) format.\n\nArguments\n\nchannels: Number of channels in the input\n\nFields\n\nchannels::Int: Number of channels\n\nDetails\n\nLearns a single scalar weight per channel\nWeights are initialized to 1.0 (identity scaling)\nUseful for lightweight residual or skip connections\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SoftGating1D","page":"Reference","title":"ESM_PINO.SoftGating1D","text":"SoftGating1D(channels::Int)\n\nA soft gating layer that applies per-channel multiplicative scaling.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SoftGating3D","page":"Reference","title":"ESM_PINO.SoftGating3D","text":"SoftGating3D(channels::Int)\n\nA soft gating layer that applies per-channel multiplicative scaling.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralConv","page":"Reference","title":"ESM_PINO.SpectralConv","text":"SpectralConv{T,N}\n\nSpectral convolution layer for Fourier Neural Operator in Lux.jl. Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nin_channels: Number of input channels\nout_channels: Number of output channels\nmodes: Tuple specifying number of low-frequency modes to retain along each spatial dimension\nT: Data type for weights (default: ComplexF32)\nN: Number of spatial dimensions (inferred from length of modes)\n\nFields\n\nin_channels::Int: Number of input channels\nout_channels::Int: Number of output channels\nmodes::NTuple{N,Int}: Number of low-frequency modes to retain along each spatial dimension\n\nDetails\n\nUses FFT to transform input to frequency domain, applies learned complex weights to low-frequency modes, and transforms back to spatial domain\nPads output back to original spatial dimensions after truncation\nWeights are initialized with Glorot-like scaling\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralKernel","page":"Reference","title":"ESM_PINO.SpectralKernel","text":"SpectralKernel{P,F}\n\nCombines a SpectralConv layer with a 1x1 convolution in parallel, followed by an activation function.   Expects input in (spatial..., channel, batch) format.\n\nArguments\n\nin_ch: Number of input channels\nout_ch: Number of output channels\nmodes: Tuple specifying number of low-frequency modes to retain in the spectral branch\nactivation: Activation function applied after combining spatial and spectral branches (default: NNlib.gelu)\n\nFields\n\nspatial_conv::P: 1x1 convolution operating directly in the spatial domain\nspectral_conv::SpectralConv: Spectral convolution layer\nactivation::F: Elementwise activation function\n\nDetails\n\nThe input is processed in parallel by a 1x1 convolution and a spectral convolution\nOutputs from both branches are summed and passed through the activation\nUseful for mixing local (spatial) and global (spectral) information\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralKernel1D","page":"Reference","title":"ESM_PINO.SpectralKernel1D","text":"SpectralKernel1D{P,F}\nCombines a SpectralConv layer with a 1x1 convolution in parallel, followed by an activation function.\n\nExpects input in (spatial, channel, batch) format.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralKernel3D","page":"Reference","title":"ESM_PINO.SpectralKernel3D","text":"SpectralKernel3D{P,F}\n\nCombines a SpectralConv layer with a 1x1 convolution in parallel, followed by an activation function. Expects input in (spatial..., channel, batch) format.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SpectralPhysicsLossParameters","page":"Reference","title":"ESM_PINO.SpectralPhysicsLossParameters","text":"SpectralPhysicsLossParameters(ν::Float64, L::Float64, N_t::Int, t_max::Float64, t_min::Float64, Δt::Float64, x_σ::Float64, x_μ::Float64)\n\nCreate a struct to hold parameters for spectral physics loss.\n\nFields\n\nν: Viscosity (scalar)\nL: Domain size (scalar)\nN_t: Number of time steps (integer)\nt_max: Maximum time (scalar)\nt_min: Minimum time (scalar)\nΔt: Time step size (scalar)\nx_σ: Standard deviation for normalization (scalar)\nx_μ: Mean for normalization (scalar)\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SphericalConv","page":"Reference","title":"ESM_PINO.SphericalConv","text":"Empty layer to test extension documentation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.SphericalKernel","page":"Reference","title":"ESM_PINO.SphericalKernel","text":"Empty layer to test extension documentation.\n\n\n\n\n\n","category":"type"},{"location":"ref/#ESM_PINO.add_noise-Tuple{AbstractArray}","page":"Reference","title":"ESM_PINO.add_noise","text":"add_noise(data::AbstractArray; noise_level::Real=0.1, noise_type::Symbol=:gaussian, relative::Bool=true, rng::AbstractRNG=Random.GLOBAL_RNG)\n\nAdd random noise to an array, supporting Gaussian or uniform distributions.\n\nArguments\n\ndata::AbstractArray: Input array to which noise will be added.\nnoise_level::Real=0.1: Magnitude of the noise. Interpreted as standard deviation for Gaussian or half-width for uniform.\nnoise_type::Symbol=:gaussian: Type of noise distribution. Options: :gaussian or :uniform.\nrelative::Bool=true: If true, scale the noise level relative to the standard deviation of data.\nrng::AbstractRNG=Random.GLOBAL_RNG: Random number generator.\n\nReturns\n\nArray: A copy of data with added noise.\n\nDetails\n\nFor :gaussian noise, samples are drawn from a normal distribution with mean 0 and specified standard deviation.\nFor :uniform noise, samples are drawn uniformly from [-noise_level, noise_level].\nIf relative=true, the noise magnitude is scaled by the standard deviation of data.\n\nExample\n\njulia> x = rand(10);\n\njulia> y = add_noise(x; noise_level=0.05, noise_type=:gaussian);\n\njulia> z = add_noise(x; noise_level=0.2, noise_type=:uniform, relative=false);\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.apply_pattern-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractArray{T}}} where {T, N}","page":"Reference","title":"ESM_PINO.apply_pattern","text":"apply_pattern(x_tr::AbstractArray{T,N}, weights::AbstractArray{T,3}) where {T,N}\n\nApply learned weight patterns to truncated Fourier coefficients.\n\nArguments\n\nx_tr::AbstractArray{T,N}: Truncated Fourier coefficients after low-pass filtering, with shape (modes..., in_channels, batch)\nweights::AbstractArray{T,4}: Complex-valued learned weights with shape (modes..., outchannels, inchannels)\n\nReturns\n\nWeighted Fourier coefficients with shape (modes..., out_channels, batch)\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.autoregressive_loss-Tuple{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer, Tuple{AbstractArray, AbstractArray}, Int64, ESM_PINO.FDPhysicsLossParameters, Float32}","page":"Reference","title":"ESM_PINO.autoregressive_loss","text":"autoregressive_loss(model::StatefulLuxLayer, (u0, target)::Tuple{AbstractArray, AbstractArray}, n_steps::Int, params::FDPhysicsLossParameters, λ::Float32)\n\nCompute autoregressive loss for a model over multiple time steps.\n\nArguments\n\nmodel: StatefulLuxLayer model\nu0: Initial state (input data)\ntarget: Target data for comparison\nn_steps: Number of time steps to propagate\nparams: FDPhysicsLossParameters struct containing physics parameters\nλ: Weighting factor for physics loss\n\nReturns\n\nTotal loss combining data loss and physics-informed loss\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.compute_k-Union{Tuple{T}, Tuple{AbstractArray{T}, T}} where T<:Real","page":"Reference","title":"ESM_PINO.compute_k","text":"compute_k(u::AbstractArray{T}, L::T) where T<:Real\n\nGenerate wavenumber array for spectral differentiation.\n\nArguments\n\nu: Template array for dimensions\nL: Domain length\n\nReturns\n\nk: Wavenumber array on GPU, reshaped for broadcasting\n\nDetails\n\nHandles even/odd array sizes differently\nAutomatically converts to GPU array\nReturns array with singleton dimensions for ND broadcasting\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.create_physics_loss-Tuple{ESM_PINO.SpectralPhysicsLossParameters}","page":"Reference","title":"ESM_PINO.create_physics_loss","text":"create_physics_loss()\n\nhelper function to create a physics loss function.\n\nArguments\n\nparams: parameters struct, pass nothing to create a zero loss function.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.dealias-Union{Tuple{T}, Tuple{AbstractArray{Complex{T}}, T}} where T<:Real","page":"Reference","title":"ESM_PINO.dealias","text":"dealias(u_hat::AbstractArray{Complex{T}}, L::T) where T<:Real\n\nApply 2/3 dealiasing filter to Fourier coefficients.\n\nArguments\n\nu_hat: Fourier coefficients (complex array)\nL: Domain length (unused in current implementation)\n\nReturns\n\nFiltered coefficients with high frequencies zeroed\n\nNotes\n\nImplements 2/3 rule for anti-aliasing\nCreates mask directly on GPU\nPreserves array dimensions for broadcasting\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.expand_pad_dims-Union{Tuple{NTuple{N, Int64}}, Tuple{N}} where N","page":"Reference","title":"ESM_PINO.expand_pad_dims","text":"expand_pad_dims(pad_dims::Dims{N}) where {N}\n\nConvert N-dimensional padding specification into format required for NNlib's pad_constant function.\n\nArguments\n\npad_dims::Dims{N}: Tuple of N integers specifying the total padding needed along each dimension\n\nReturns\n\nNTuple{2N,Int}: Tuple of 2N integers specifying padding for both sides of each dimension, where padding is applied only at the end of each dimension (start padding is always 0)\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.low_pass-Tuple{AbstractArray, Any}","page":"Reference","title":"ESM_PINO.low_pass","text":"low_pass(x_ft, modes)\n\nApply a low-pass filter to a Fourier-transformed array by retaining only the lowest frequency modes.\n\nArguments\n\nx_ft: A Fourier-transformed array with at least 2 trailing dimensions\nmodes: A tuple or array specifying the number of low-frequency modes to keep along each leading dimension\n\nReturns\n\nA view of the input array x_ft containing only the specified low-frequency modes, preserving the last two dimensions in full\n\nDetails\n\nThe function creates a view that selects the first modes[i] elements along each leading dimension i, while keeping all elements of the last two dimensions. This effectively implements a low-pass filter in Fourier space by truncating high-frequency modes.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.meshgrid-Tuple{Any, Any}","page":"Reference","title":"ESM_PINO.meshgrid","text":"meshgrid(x, y)\n\nGenerates a 2D meshgrid from vectors x and y.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.mse_loss_function-Tuple{LuxCore.StatefulLuxLayerImpl.StatefulLuxLayer, AbstractArray, AbstractArray}","page":"Reference","title":"ESM_PINO.mse_loss_function","text":"mse_loss_function(u::StatefulLuxLayer, target::AbstractArray, xt::AbstractArray)\n\nStandard mean squared error loss.\n\nArguments\n\nu: Neural network\ntarget: Ground truth values\nu_t1: Network inputs\n\nReturns\n\nMSE between network output and target\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.normalize_data-Tuple{Any}","page":"Reference","title":"ESM_PINO.normalize_data","text":"normalize_data(data)\n\nNormalize an array to zero mean and unit variance.\n\nArguments\n\n-data: Input array.\n\nReturns\n\n-(normalized_data, μ, σ): A tuple containing:     normalized_data: The normalized array.     μ: The mean of the original data.     σ: The standard deviation of the original data.\n\n\n\n\n\n","category":"method"},{"location":"ref/#ESM_PINO.select_loss_function","page":"Reference","title":"ESM_PINO.select_loss_function","text":"select_loss_function()\n\nHelper function to pass a valid loss function to Training.singletrainstep. Selects a loss function based on the provided physics-informed loss function, in the standard workflow generated with createphysicsloss.\n\nArguments\n\nPI_loss: Physics-informed loss function (default is a zero loss function)\n\n\n\n\n\n","category":"function"},{"location":"ref/#ESM_PINO.spectral_derivative-Union{Tuple{T}, Tuple{AbstractArray{T}, T}} where T<:Real","page":"Reference","title":"ESM_PINO.spectral_derivative","text":"spectral_derivative(u::AbstractArray{T}, L::T) where T<:Real\n\nCompute first and second spatial derivatives using FFT spectral methods.\n\nArguments\n\nu: Input array (real-valued), assumed to be on GPU. First dimension is spatial.\nL: Domain length in spatial dimension.\n\nReturns\n\ndu: First derivative (real array)\nd2u: Second derivative (real array)\n\nNotes\n\nUses FFT/iFFT with wavenumbers from compute_k\nAssumes periodic boundary conditions\nMaintains input array type/location (GPU/CPU)\nOutput derivatives are real-valued arrays\n\n\n\n\n\n","category":"method"},{"location":"#ESM_PINO","page":"Home","title":"ESM_PINO","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ESM_PINO.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The SFNO components are empty-defined in the main module and work through extensions by loading two different backends for the Spherical Harmonics transforms: QG3.jl (supports Zygote for automatic differentiation), and SpeedyWeather.jl (still work in progress)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"ref.md\", \"extensions/QG3.md\", \"extensions/SpeedyWeather.md\"]\nDepth = 2","category":"page"}]
}
